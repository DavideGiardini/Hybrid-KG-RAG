{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from tqdm import tqdm\n",
    "import config.EnvLoader as el\n",
    "\n",
    "URI = \"neo4j://localhost\"\n",
    "AUTH = (\"neo4j\", el.NEO4J_PWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('extracted_chunks_hybrid_multihop_468.json', 'r') as file:\n",
    "    extracted_chunks_hybrid_tot = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Open the file in binary mode \n",
    "with open('multihop_eval_df.pkl', 'rb') as file: \n",
    "\tmh_eval = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_eval = mh_eval[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# Initialize Azure Embeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_key=el.OPENAI_API_KEY,\n",
    "    azure_endpoint=el.AZURE_ENDPOINT,\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_diz = {}\n",
    "\n",
    "for obs in mh_eval:\n",
    "    q_diz[obs['question'].strip()] = embeddings.embed_query(obs['question'].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Retrieval on Multihop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_chunks_naive = {}\n",
    "\n",
    "for obs in mh_eval:\n",
    "    question = obs['question'].strip()\n",
    "    answer = obs['answer'].strip()\n",
    "    diz = {}\n",
    "    for i in [4,6,8]:\n",
    "        # Search for top n chunk\n",
    "        with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "            retrieved_chunks, _, _ = driver.execute_query(\n",
    "                \"\"\"CALL db.index.vector.queryNodes(\"vector\", 100, $embedding)\n",
    "                    YIELD node, score\n",
    "                    RETURN elementId(node), node.uri, node.text\n",
    "                    LIMIT $n_chunks\"\"\",\n",
    "                embedding=q_diz[question], n_chunks = i\n",
    "            )\n",
    "        top_chunks_ids = [x[\"elementId(node)\"] for x in retrieved_chunks]\n",
    "        top_chunks = [x[\"node.uri\"] for x in retrieved_chunks]\n",
    "        context = [x[\"node.text\"] for x in retrieved_chunks]\n",
    "        diz[i] = {\n",
    "            'top_chunks_ids': top_chunks_ids,\n",
    "            'top_chunks': top_chunks,\n",
    "            'context': context\n",
    "        }\n",
    "    extracted_chunks_naive[question] = diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_precision = {4:[],6:[],8:[]}\n",
    "naive_recall = {4:[],6:[],8:[]}\n",
    "naive_detection = {4:[],6:[],8:[]}\n",
    "\n",
    "n_chunks = [4,6,8]\n",
    "\n",
    "for obs in mh_eval:\n",
    "    question = obs[\"question\"].strip()\n",
    "    answers = obs[\"chunks_used\"]\n",
    "    for n_chunk in n_chunks:\n",
    "        found_answers = [x for x in answers if x in extracted_chunks_naive[question][n_chunk]['top_chunks']]\n",
    "        # Append results for Chunk RAG\n",
    "        naive_precision[n_chunk].append(len(found_answers)/n_chunk)\n",
    "        naive_recall[n_chunk].append(len(found_answers)/len(answers))\n",
    "        naive_detection[n_chunk].append(1 if len(found_answers) == len(answers) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 4 chunks\n",
      "Precision: 0.175\n",
      "Recall: 0.357\n",
      "Detection: 0.09\n",
      "Results for 6 chunks\n",
      "Precision: 0.138\n",
      "Recall: 0.418\n",
      "Detection: 0.16\n",
      "Results for 8 chunks\n",
      "Precision: 0.111\n",
      "Recall: 0.448\n",
      "Detection: 0.18\n"
     ]
    }
   ],
   "source": [
    "# Results for 4 retrieved chunks\n",
    "for i in n_chunks:\n",
    "    print(f\"Results for {i} chunks\")\n",
    "    print(f\"Precision: {round(sum(naive_precision[i])/100,3)}\")\n",
    "    print(f\"Recall: {round(sum(naive_recall[i])/100,3)}\")\n",
    "    print(f\"Detection: {round(sum(naive_detection[i])/100,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Retrieval on MultiHop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'Question: Which song did Sam Smith contribute to with Band Aid 30 to raise money for the 2014 Ebola crisis?\\nAnswer: Sam Smith contributed to the song \"Do They Know It\\'s Christmas?\" with Band Aid 30 to raise money for the 2014 Ebola crisis.\\nChunk used: chunk0, chunk2',\n",
       " 'context': 'INPUT:\\n- chunk0: UK Singles Chart records and statistics#Number ones by different artists#1\\nCurrently two songs have reached number one four times by different artists: \"Unchained Melody\" and \"Do They Know It\\'s Christmas?\". Three of the versions of \"Unchained Melody\" sold over a million copies, while two of the versions of \"Do They Know It\\'s Christmas?\" achieved this. The lyrics of the Band Aid 30 version were changed to give it relevance to the 2014 Ebola crisis. Numerous artists appear on more than one version of \"Do They Know It\\'s Christmas?\".\\n- chunk2: Sam Smith (singer)#Music career#2014–2016: In the Lonely Hour and international success#4\\nIn June 2014, Smith first appeared on the cover of The Fader in its 92nd issue. In August 2014, Smith\\'s single \"Stay with Me\" was named Variance Magazine\\'s Song of Summer. Smith performed \"Stay With Me\" live at the 2014 MTV Video Music Awards on 24 August at The Forum in Inglewood, California. On 15 November 2014, Smith joined the charity group Band Aid 30 along with other British and Irish pop acts, recording the latest version of the track \"Do They Know It\\'s Christmas?\" at Sarm West Studios in Notting Hill, London, to raise money for the 2014 Ebola crisis in Western Africa.\\n- entity: Band Aid 30 (MusicalArtist)\\nOUTPUT:\\n',\n",
       " 'entity': 'Band Aid 30 (MusicalArtist)',\n",
       " 'chunks_used': ['UK Singles Chart records and statistics#Number ones by different artists#1',\n",
       "  'Sam Smith (singer)#Music career#2014–2016: In the Lonely Hour and international success#4'],\n",
       " 'question': ' Which song did Sam Smith contribute to with Band Aid 30 to raise money for the 2014 Ebola crisis?',\n",
       " 'answer': ' Sam Smith contributed to the song \"Do They Know It\\'s Christmas?\" with Band Aid 30 to raise money for the 2014 Ebola crisis.',\n",
       " 'score': 10}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_precision = {4:[],6:[],8:[]}\n",
    "hybrid_recall = {4:[],6:[],8:[]}\n",
    "hybrid_detection = {4:[],6:[],8:[]}\n",
    "\n",
    "n_chunks = [4,6,8]\n",
    "\n",
    "for obs in mh_eval:\n",
    "    question = obs[\"question\"].strip()\n",
    "    answers = obs[\"chunks_used\"]\n",
    "    # Search answers ID\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        retrieved_chunks, _, _ = driver.execute_query(\n",
    "            \"\"\"WITH $uri_ids AS list\n",
    "            MATCH (a:Chunk)\n",
    "            WHERE a.uri IN list\n",
    "            RETURN elementId(a)\"\"\",\n",
    "            uri_ids=answers\n",
    "        )\n",
    "    answers_ids = [int(x[\"elementId(a)\"].split(\":\")[-1]) for x in retrieved_chunks]\n",
    "    for idx, n_chunk in enumerate(n_chunks):\n",
    "        found_answers = [x for x in answers_ids if x in extracted_chunks_hybrid_tot[\" \" + question][idx]]\n",
    "        # Append results for Chunk RAG\n",
    "        hybrid_precision[n_chunk].append(len(found_answers)/n_chunk)\n",
    "        hybrid_recall[n_chunk].append(len(found_answers)/len(answers))\n",
    "        hybrid_detection[n_chunk].append(1 if len(found_answers) == len(answers) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 4 chunks\n",
      "Precision: 0.302\n",
      "Recall: 0.599\n",
      "Detection: 0.33\n",
      "Results for 6 chunks\n",
      "Precision: 0.232\n",
      "Recall: 0.688\n",
      "Detection: 0.43\n",
      "Results for 8 chunks\n",
      "Precision: 0.18\n",
      "Recall: 0.711\n",
      "Detection: 0.48\n"
     ]
    }
   ],
   "source": [
    "for i in n_chunks:\n",
    "    print(f\"Results for {i} chunks\")\n",
    "    print(f\"Precision: {round(sum(hybrid_precision[i])/100,3)}\")\n",
    "    print(f\"Recall: {round(sum(hybrid_recall[i])/100,3)}\")\n",
    "    print(f\"Detection: {round(sum(hybrid_detection[i])/100,3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
