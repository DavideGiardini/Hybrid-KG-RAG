{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDEXING\n",
    "\n",
    "This is the node used to index all of the node of the Graph with ada v2 (through AzureOpenAIEmbeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "import config.EnvLoader as el\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the neo4j DB\n",
    "URI = \"neo4j://localhost\"\n",
    "AUTH = (\"neo4j\", el.NEO4J_PWD)\n",
    "os.environ[\"NEO4J_URI\"] = URI\n",
    "os.environ[\"NEO4J_USERNAME\"] = AUTH[0]\n",
    "os.environ[\"NEO4J_PASSWORD\"] = AUTH[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure Embeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_key=el.OPENAI_API_KEY,\n",
    "    azure_endpoint=el.AZURE_ENDPOINT,\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page and SubChapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid rate limit errors, the function from_existing_graph was modified in this way\n",
    "\n",
    "import time\n",
    "\n",
    "finished_at = datetime.datetime(2009, 1, 6, 15, 8, 24, 78915)\n",
    "while True:\n",
    "    fetch_query = (\n",
    "        f\"MATCH (n:`{node_label}`) \"\n",
    "        f\"WHERE n.{embedding_node_property} IS null \"\n",
    "        \"AND any(k in $props WHERE n[k] IS NOT null) \"\n",
    "        f\"RETURN elementId(n) AS id, reduce(str='',\"\n",
    "        \"k IN $props | str + '\\\\n' + k + ':' + coalesce(n[k], '')) AS text \"\n",
    "        \"LIMIT 1200\"\n",
    "    )\n",
    "\n",
    "    delta = datetime.datetime.now() - finished_at\n",
    "    if delta.seconds < 60:\n",
    "        time.sleep(65 - delta.seconds)\n",
    "\n",
    "    data = store.query(fetch_query, params={\"props\": text_node_properties})\n",
    "    text_embeddings = embedding.embed_documents([el[\"text\"] for el in data])\n",
    "\n",
    "    params = {\n",
    "        \"data\": [\n",
    "            {\"id\": el[\"id\"], \"embedding\": embedding}\n",
    "            for el, embedding in zip(data, text_embeddings)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    store.query(\n",
    "        \"UNWIND $data AS row \"\n",
    "        f\"MATCH (n:`{node_label}`) \"\n",
    "        \"WHERE elementId(n) = row.id \"\n",
    "        f\"CALL db.create.setVectorProperty(n, \"\n",
    "        f\"'{embedding_node_property}', row.embedding) \"\n",
    "        \"YIELD node RETURN count(*)\",\n",
    "        params=params,\n",
    "    )\n",
    "    # If embedding calculation should be stopped\n",
    "    if len(data) < 1200:\n",
    "        break\n",
    "\n",
    "    finished_at = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings 426m\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"vector\",\n",
    "    node_label=\"Page\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings 73m\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"vector\",\n",
    "    node_label=\"SubChapter\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid rate limit errors, the function from_existing_graph was modified in this way\n",
    "\n",
    "import datetime\n",
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "finished_at = datetime.datetime(2009, 1, 6, 15, 8, 24, 78915)\n",
    "while True:\n",
    "    fetch_query = (\n",
    "        f\"MATCH (n:`{node_label}`) \"\n",
    "        f\"WHERE n.{embedding_node_property} IS null \"\n",
    "        \"AND any(k in $props WHERE n[k] IS NOT null) \"\n",
    "        f\"RETURN elementId(n) AS id, reduce(str='',\"\n",
    "        \"k IN $props | str + '\\\\n' + k + ':' + coalesce(n[k], '')) AS text \"\n",
    "        \"LIMIT 1200\"\n",
    "    )\n",
    "    data = store.query(fetch_query, params={\"props\": text_node_properties})\n",
    "    new_data = []\n",
    "    total_tokens = 0\n",
    "    for el in data:\n",
    "        total_tokens += len(encoding.encode(el[\"text\"]))\n",
    "        if total_tokens > 200000:\n",
    "            break\n",
    "        new_data.append(el)\n",
    "\n",
    "    delta = datetime.datetime.now() - finished_at\n",
    "    if delta.seconds < 60:\n",
    "        time.sleep(65 - delta.seconds)\n",
    "\n",
    "    text_embeddings = embedding.embed_documents([el[\"text\"] for el in new_data])\n",
    "\n",
    "    params = {\n",
    "        \"new_data\": [\n",
    "            {\"id\": el[\"id\"], \"embedding\": embedding}\n",
    "            for el, embedding in zip(new_data, text_embeddings)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    store.query(\n",
    "        \"UNWIND $new_data AS row \"\n",
    "        f\"MATCH (n:`{node_label}`) \"\n",
    "        \"WHERE elementId(n) = row.id \"\n",
    "        f\"CALL db.create.setVectorProperty(n, \"\n",
    "        f\"'{embedding_node_property}', row.embedding) \"\n",
    "        \"YIELD node RETURN count(*)\",\n",
    "        params=params,\n",
    "    )\n",
    "    # If embedding calculation should be stopped\n",
    "    if len(data) < 1200 and len(data) == len(new_data):\n",
    "        break\n",
    "\n",
    "    finished_at = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings 203m\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"vector\",\n",
    "    node_label=\"Chunk\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationships\n",
    "Embedding the relationships of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all distinct relationships\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    rel_lst, summary, keys = driver.execute_query(\n",
    "        \"\"\"MATCH ()-[r:vector_rel]->()\n",
    "        RETURN DISTINCT r.text;\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7668"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rel_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7668/7668 [43:13<00:00,  2.96it/s] \n"
     ]
    }
   ],
   "source": [
    "relationship_embeddings = []\n",
    "\n",
    "for rel in tqdm(rel_lst):\n",
    "    new_embedding = embeddings.embed_query(rel['r.text'])\n",
    "    relationship_embeddings.append(new_embedding)\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        result, summary, keys = driver.execute_query(\n",
    "            \"\"\"MATCH ()-[r:vector_rel {text: $text}]->()\n",
    "            SET r.embedding = $embedding;\"\"\",\n",
    "            text= rel['r.text'], embedding=new_embedding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create relationship vector index\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    result, summary, keys = driver.execute_query(\n",
    "        \"\"\"CREATE VECTOR INDEX vector_rel_index\n",
    "        FOR ()-[r:vector_rel]-() ON (r.embedding)\n",
    "        OPTIONS {indexConfig: {\n",
    "        `vector.dimensions`: 1536,\n",
    "        `vector.similarity_function`: 'cosine'\n",
    "        }}\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "Embedding the question of the NQ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    questions, _, _ = driver.execute_query(\n",
    "        \"\"\"MATCH (a:Chunk)\n",
    "        WHERE a.is_answer_of IS NOT NULL\n",
    "        RETURN DISTINCT a.is_answer_of\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5223"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5223/5223 [12:23<00:00,  7.03it/s]\n"
     ]
    }
   ],
   "source": [
    "embedded_questions = {}\n",
    "for question in tqdm(questions):\n",
    "    question = question[\"a.is_answer_of\"]\n",
    "    embedded_questions[question] = embeddings.embed_query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('embedded_questions.pkl', 'wb') as f:\n",
    "    pickle.dump(embedded_questions, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
